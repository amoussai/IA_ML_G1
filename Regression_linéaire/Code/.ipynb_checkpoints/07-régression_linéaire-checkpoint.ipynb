{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression Linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les trois premiers modules importés sont pandas pour la manipulation des données, math pour calculer des racines carrées et matplotlib.pyplot pour réaliser des graphiques. Les autres modules importés sont définis comme suit :\n",
    "\n",
    "    sklearn.model_selection : ce module nous permettra d’avoir accès à la fonction train_test_split qui nous sera utile pour la séparation de nos données en deux groupes : un premier groupe de données pour l’entraînement d’un modèle et un deuxième groupe de données pour l’évaluation d’un modèle.\n",
    "\n",
    "    sklearn.linear_model : ce module nous donnera accès à la fonction LinearRegression qui sera utile pour instancier un algorithme de régression linéaire.\n",
    "\n",
    "    sklearn.metrics : ce module nous donnera accès aux deux fonctions mean_squared_error et r2_score qui, comme leur nom l’indique, vont nous servir pour le calcul de la racine carrée de la moyenne des erreurs d’un modèle et de la métrique de performance R2 qui sera détaillée dans la suite de ce chapitre.\n",
    "\n",
    "    preprocessing : ce module va nous donner accès à la fonction de normalisation de données dont nous aurons besoin afin de représenter nos données dans des échelles relatives à la moyenne zéro et leur écart-type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Les variables T9, T12 et T15 correspondent respectivement à des prélèvements de température à 9 h, 12 h et 15 h.\n",
    "\n",
    "    Les variables Ne9, Ne12 et Ne15 correspondent respectivement à des prélèvements de nébulosité à 9 h, 12 h et 15 h.\n",
    "\n",
    "    Les variables Vx9, Vx12 et Vx15 correspondent respectivement à des prélèvements de vent à 9 h, 12 h et 15 h.\n",
    "\n",
    "    Deux variables qualitatives Vent et Pluie. Ces deux variables ne seront pas utilisées lors de l’estimation des paramètres de notre modèle, puisqu’elles ne sont pas de type quantitatif. Néanmoins, pour les inclure dans une expérimentation, il suffirait de les transformer en valeurs numériques. Par exemple, les valeurs sec de la variable Pluie peuvent être remplacées par la valeur 1, et les valeurs Pluie de cette même variable Pluie peuvent être remplacées par la valeur 2. De même, nous pouvons transformer les valeurs de la variable Vent comme suit : Nord = 1, Sud = 2, Est = 3 et West = 4.\n",
    "\n",
    "    La variable Date correspond aux dates des prélèvements. Comme pour les deux variables Vent et Pluie, cette variable ne sera pas utilisée lors de l’estimation du modèle.\n",
    "\n",
    "    Enfin, la variable Max03v correspond à la mesure maximum de la concentration d’ozone de la veille.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MaxO3</th>\n",
       "      <th>T9</th>\n",
       "      <th>T12</th>\n",
       "      <th>T15</th>\n",
       "      <th>Ne9</th>\n",
       "      <th>Ne12</th>\n",
       "      <th>Ne15</th>\n",
       "      <th>Vx9</th>\n",
       "      <th>Vx12</th>\n",
       "      <th>Vx15</th>\n",
       "      <th>MaxO3v</th>\n",
       "      <th>Vent</th>\n",
       "      <th>Pluie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010601</td>\n",
       "      <td>87</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>84</td>\n",
       "      <td>Nord</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010602</td>\n",
       "      <td>82</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>87</td>\n",
       "      <td>Nord</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010603</td>\n",
       "      <td>92</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>1.8794</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>82</td>\n",
       "      <td>Est</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010604</td>\n",
       "      <td>114</td>\n",
       "      <td>16.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>-0.1736</td>\n",
       "      <td>92</td>\n",
       "      <td>Nord</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010605</td>\n",
       "      <td>94</td>\n",
       "      <td>17.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-2.9544</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>114</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>20010925</td>\n",
       "      <td>84</td>\n",
       "      <td>13.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.2856</td>\n",
       "      <td>76</td>\n",
       "      <td>Sud</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>20010927</td>\n",
       "      <td>77</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>-1.3681</td>\n",
       "      <td>71</td>\n",
       "      <td>Sud</td>\n",
       "      <td>Pluie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>20010928</td>\n",
       "      <td>99</td>\n",
       "      <td>16.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>77</td>\n",
       "      <td>Sud</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>20010929</td>\n",
       "      <td>83</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.7588</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>99</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>Pluie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20010930</td>\n",
       "      <td>70</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0419</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>83</td>\n",
       "      <td>Sud</td>\n",
       "      <td>Sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  MaxO3    T9   T12   T15  Ne9  Ne12  Ne15     Vx9    Vx12  \\\n",
       "0    20010601     87  15.6  18.5  18.4    4     4     8  0.6946 -1.7101   \n",
       "1    20010602     82  17.0  18.4  17.7    5     5     7 -4.3301 -4.0000   \n",
       "2    20010603     92  15.3  17.6  19.5    2     5     4  2.9544  1.8794   \n",
       "3    20010604    114  16.2  19.7  22.5    1     1     0  0.9848  0.3473   \n",
       "4    20010605     94  17.4  20.5  20.4    8     8     7 -0.5000 -2.9544   \n",
       "..        ...    ...   ...   ...   ...  ...   ...   ...     ...     ...   \n",
       "107  20010925     84  13.3  17.7  17.8    3     5     6  0.0000 -1.0000   \n",
       "108  20010927     77  16.2  20.8  22.1    6     5     5 -0.6946 -2.0000   \n",
       "109  20010928     99  16.9  23.0  22.6    6     4     7  1.5000  0.8682   \n",
       "110  20010929     83  16.9  19.8  22.1    6     5     3 -4.0000 -3.7588   \n",
       "111  20010930     70  15.7  18.6  20.7    7     7     7  0.0000 -1.0419   \n",
       "\n",
       "       Vx15  MaxO3v   Vent  Pluie  \n",
       "0   -0.6946      84   Nord    Sec  \n",
       "1   -3.0000      87   Nord    Sec  \n",
       "2    0.5209      82    Est    Sec  \n",
       "3   -0.1736      92   Nord    Sec  \n",
       "4   -4.3301     114  Ouest    Sec  \n",
       "..      ...     ...    ...    ...  \n",
       "107 -1.2856      76    Sud    Sec  \n",
       "108 -1.3681      71    Sud  Pluie  \n",
       "109  0.8682      77    Sud    Sec  \n",
       "110 -4.0000      99  Ouest  Pluie  \n",
       "111 -4.0000      83    Sud    Sec  \n",
       "\n",
       "[112 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/ozone.csv', sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isoler dans un vecteur séparé la variable à expliquer y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"MaxO3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       87\n",
       "1       82\n",
       "2       92\n",
       "3      114\n",
       "4       94\n",
       "      ... \n",
       "107     84\n",
       "108     77\n",
       "109     99\n",
       "110     83\n",
       "111     70\n",
       "Name: MaxO3, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garder dans le DataFrame data que les dix variables explicatives T9, T12, T15, Ne9, Ne12, Ne15, Vx9, Vx12, Vx15 et Max03v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[\n",
    "           ['T9', 'T12', 'T15', 'Ne9', 'Ne12', 'Ne15', 'Vx9',\n",
    "            'Vx12', 'Vx15', 'MaxO3v']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T9</th>\n",
       "      <th>T12</th>\n",
       "      <th>T15</th>\n",
       "      <th>Ne9</th>\n",
       "      <th>Ne12</th>\n",
       "      <th>Ne15</th>\n",
       "      <th>Vx9</th>\n",
       "      <th>Vx12</th>\n",
       "      <th>Vx15</th>\n",
       "      <th>MaxO3v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>1.8794</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>-0.1736</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-2.9544</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>13.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.2856</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>16.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>-1.3681</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>16.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>16.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.7588</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>15.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0419</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T9   T12   T15  Ne9  Ne12  Ne15     Vx9    Vx12    Vx15  MaxO3v\n",
       "0    15.6  18.5  18.4    4     4     8  0.6946 -1.7101 -0.6946      84\n",
       "1    17.0  18.4  17.7    5     5     7 -4.3301 -4.0000 -3.0000      87\n",
       "2    15.3  17.6  19.5    2     5     4  2.9544  1.8794  0.5209      82\n",
       "3    16.2  19.7  22.5    1     1     0  0.9848  0.3473 -0.1736      92\n",
       "4    17.4  20.5  20.4    8     8     7 -0.5000 -2.9544 -4.3301     114\n",
       "..    ...   ...   ...  ...   ...   ...     ...     ...     ...     ...\n",
       "107  13.3  17.7  17.8    3     5     6  0.0000 -1.0000 -1.2856      76\n",
       "108  16.2  20.8  22.1    6     5     5 -0.6946 -2.0000 -1.3681      71\n",
       "109  16.9  23.0  22.6    6     4     7  1.5000  0.8682  0.8682      77\n",
       "110  16.9  19.8  22.1    6     5     3 -4.0000 -3.7588 -4.0000      99\n",
       "111  15.7  18.6  20.7    7     7     7  0.0000 -1.0419 -4.0000      83\n",
       "\n",
       "[112 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En analysant visuellement les quelques enregistrements ci-dessus du DataFrame data, nous pouvons constater que les variables T9, T12 et T15 sont définies dans des échelles relativement comparables entre elles, puisque ces trois variables mesurent la température, mais elles sont très différentes des échelles dans lesquelles sont définies les variables Ne9, Ne12, Ne15. Ces différences sont encore plus importantes entre les variables T9, T12, T15 et les variables Vx9, Vx12, Vx15. De même, les échelles des variables Ne9, Ne12 et Ne15 sont clairement différentes de celles des variables Vx9, Vx12 et Vx15. Enfin, l’échelle dans laquelle est définie la variable MaxO3v est beaucoup plus large que les échelles de toutes les autres variables.\n",
    "\n",
    "Pour avoir le cœur net quant aux échelles de définition de nos dix variables, nous allons calculer les statistiques de base de notre DataFrame data.\n",
    "\n",
    "En comparant ces statistiques, on voit plus clairement et de façon plus certaine les différences des distributions associées aux dix variables. Par exemple, on note que les valeurs minimales et maximales des variables T9, T12 et T15 sont très différentes des valeurs minimales et maximales des variables Ne9, Ne12, Ne15 et ces différences sont plus importantes avec les valeurs minimales et maximales des variables Vx9, Vx12 et Vx15.  \n",
    "\n",
    "Également, on voit que les valeurs minimales et maximales des variables T9, T12, T15 sont peu différentes et ces différences sont liées aux horaires correspondant aux prises de ces températures. Le matin, la température T9 est généralement inférieure à la température T12 prise à 12h, et cette dernière est généralement inférieure à la température T15 qui est prise à 15h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T9</th>\n",
       "      <th>T12</th>\n",
       "      <th>T15</th>\n",
       "      <th>Ne9</th>\n",
       "      <th>Ne12</th>\n",
       "      <th>Ne15</th>\n",
       "      <th>Vx9</th>\n",
       "      <th>Vx12</th>\n",
       "      <th>Vx15</th>\n",
       "      <th>MaxO3v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.360714</td>\n",
       "      <td>21.526786</td>\n",
       "      <td>22.627679</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5.017857</td>\n",
       "      <td>4.830357</td>\n",
       "      <td>-1.214346</td>\n",
       "      <td>-1.611004</td>\n",
       "      <td>-1.690683</td>\n",
       "      <td>90.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.122726</td>\n",
       "      <td>4.042321</td>\n",
       "      <td>4.530859</td>\n",
       "      <td>2.594916</td>\n",
       "      <td>2.281860</td>\n",
       "      <td>2.332259</td>\n",
       "      <td>2.632742</td>\n",
       "      <td>2.795673</td>\n",
       "      <td>2.810198</td>\n",
       "      <td>28.276853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.878500</td>\n",
       "      <td>-7.878500</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.200000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>19.275000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-3.276450</td>\n",
       "      <td>-3.564700</td>\n",
       "      <td>-3.939200</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.800000</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.866000</td>\n",
       "      <td>-1.879400</td>\n",
       "      <td>-1.549650</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.925000</td>\n",
       "      <td>23.550000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.196200</td>\n",
       "      <td>6.577800</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T9         T12         T15         Ne9        Ne12        Ne15  \\\n",
       "count  112.000000  112.000000  112.000000  112.000000  112.000000  112.000000   \n",
       "mean    18.360714   21.526786   22.627679    4.928571    5.017857    4.830357   \n",
       "std      3.122726    4.042321    4.530859    2.594916    2.281860    2.332259   \n",
       "min     11.300000   14.000000   14.900000    0.000000    0.000000    0.000000   \n",
       "25%     16.200000   18.600000   19.275000    3.000000    4.000000    3.000000   \n",
       "50%     17.800000   20.550000   22.050000    6.000000    5.000000    5.000000   \n",
       "75%     19.925000   23.550000   25.400000    7.000000    7.000000    7.000000   \n",
       "max     27.000000   33.500000   35.500000    8.000000    8.000000    8.000000   \n",
       "\n",
       "              Vx9        Vx12        Vx15      MaxO3v  \n",
       "count  112.000000  112.000000  112.000000  112.000000  \n",
       "mean    -1.214346   -1.611004   -1.690683   90.571429  \n",
       "std      2.632742    2.795673    2.810198   28.276853  \n",
       "min     -7.878500   -7.878500   -9.000000   42.000000  \n",
       "25%     -3.276450   -3.564700   -3.939200   71.000000  \n",
       "50%     -0.866000   -1.879400   -1.549650   82.500000  \n",
       "75%      0.694600    0.000000    0.000000  106.000000  \n",
       "max      5.196200    6.577800    5.000000  166.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de remédier à ce problème d’échelle de définition des variables, nous allons procéder à leur normalisation. Pour cela, nous utilisons la normalisation standard qui consiste, pour une variable donnée, à retirer la moyenne de chaque valeur de cette variable et diviser le résultat de cette soustraction par l’écart-type de cette même variable. Ainsi, les valeurs des variables sont représentées par leurs distances en termes d’écart-type à leur moyenne zéro. Pour réaliser cette normalisation standard, suivez les étapes ci-après."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n",
      "/tmp/ipykernel_18303/1106372395.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataToNormalize[col]=res\n"
     ]
    }
   ],
   "source": [
    "def normalization(dataToNormalize):\n",
    "    columns = dataToNormalize.columns\n",
    "    for col in columns:\n",
    "        x = dataToNormalize[[col]].values.astype(float)\n",
    "        standard_normalization = preprocessing.StandardScaler()\n",
    "        res = standard_normalization.fit_transform(x)\n",
    "        dataToNormalize[col]=res\n",
    "        \n",
    "normalization(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction récupère une par une les variables d’un DataFrame reçu en paramètre, puis elle transforme les valeurs de ces variables en utilisant la normalisation standard. Cette normalisation standard est réalisée par un algorithme créé avec la fonction preprocessing.StandardScaler() qui est appliqué sur une variable x et le résultat de cette transformation sera enregistré dans le DataFrame reçu en paramètre à la place des valeurs d’origine de la variable qui a subi la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T9</th>\n",
       "      <th>T12</th>\n",
       "      <th>T15</th>\n",
       "      <th>Ne9</th>\n",
       "      <th>Ne12</th>\n",
       "      <th>Ne15</th>\n",
       "      <th>Vx9</th>\n",
       "      <th>Vx12</th>\n",
       "      <th>Vx15</th>\n",
       "      <th>MaxO3v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.888045</td>\n",
       "      <td>-0.752140</td>\n",
       "      <td>-0.937279</td>\n",
       "      <td>-0.359451</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>1.365152</td>\n",
       "      <td>0.728338</td>\n",
       "      <td>-0.035606</td>\n",
       "      <td>0.356046</td>\n",
       "      <td>-0.233441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.437704</td>\n",
       "      <td>-0.776989</td>\n",
       "      <td>-1.092469</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>-1.188782</td>\n",
       "      <td>-0.858374</td>\n",
       "      <td>-0.468010</td>\n",
       "      <td>-0.126870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.984547</td>\n",
       "      <td>-0.975785</td>\n",
       "      <td>-0.693408</td>\n",
       "      <td>-1.133653</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>-0.357631</td>\n",
       "      <td>1.590540</td>\n",
       "      <td>1.254113</td>\n",
       "      <td>0.790522</td>\n",
       "      <td>-0.304488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.695042</td>\n",
       "      <td>-0.453946</td>\n",
       "      <td>-0.028306</td>\n",
       "      <td>-1.520753</td>\n",
       "      <td>-1.768695</td>\n",
       "      <td>-2.080415</td>\n",
       "      <td>0.839060</td>\n",
       "      <td>0.703625</td>\n",
       "      <td>0.542276</td>\n",
       "      <td>0.050748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.309035</td>\n",
       "      <td>-0.255151</td>\n",
       "      <td>-0.493878</td>\n",
       "      <td>1.188953</td>\n",
       "      <td>1.312765</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>0.272551</td>\n",
       "      <td>-0.482687</td>\n",
       "      <td>-0.943449</td>\n",
       "      <td>0.832266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.627892</td>\n",
       "      <td>-0.950935</td>\n",
       "      <td>-1.070299</td>\n",
       "      <td>-0.746552</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.503760</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.219536</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>-0.517629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.695042</td>\n",
       "      <td>-0.180602</td>\n",
       "      <td>-0.116987</td>\n",
       "      <td>0.414751</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>0.073064</td>\n",
       "      <td>0.198303</td>\n",
       "      <td>-0.139768</td>\n",
       "      <td>0.115306</td>\n",
       "      <td>-0.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-0.469871</td>\n",
       "      <td>0.366086</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>0.414751</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>1.035629</td>\n",
       "      <td>0.890786</td>\n",
       "      <td>0.914663</td>\n",
       "      <td>-0.482105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.469871</td>\n",
       "      <td>-0.429097</td>\n",
       "      <td>-0.116987</td>\n",
       "      <td>0.414751</td>\n",
       "      <td>-0.007861</td>\n",
       "      <td>-0.788327</td>\n",
       "      <td>-1.062836</td>\n",
       "      <td>-0.771710</td>\n",
       "      <td>-0.825457</td>\n",
       "      <td>0.299413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-0.855878</td>\n",
       "      <td>-0.727290</td>\n",
       "      <td>-0.427368</td>\n",
       "      <td>0.801852</td>\n",
       "      <td>0.872556</td>\n",
       "      <td>0.934456</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.204481</td>\n",
       "      <td>-0.825457</td>\n",
       "      <td>-0.268964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           T9       T12       T15       Ne9      Ne12      Ne15       Vx9  \\\n",
       "0   -0.888045 -0.752140 -0.937279 -0.359451 -0.448069  1.365152  0.728338   \n",
       "1   -0.437704 -0.776989 -1.092469  0.027650 -0.007861  0.934456 -1.188782   \n",
       "2   -0.984547 -0.975785 -0.693408 -1.133653 -0.007861 -0.357631  1.590540   \n",
       "3   -0.695042 -0.453946 -0.028306 -1.520753 -1.768695 -2.080415  0.839060   \n",
       "4   -0.309035 -0.255151 -0.493878  1.188953  1.312765  0.934456  0.272551   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "107 -1.627892 -0.950935 -1.070299 -0.746552 -0.007861  0.503760  0.463320   \n",
       "108 -0.695042 -0.180602 -0.116987  0.414751 -0.007861  0.073064  0.198303   \n",
       "109 -0.469871  0.366086 -0.006136  0.414751 -0.448069  0.934456  1.035629   \n",
       "110 -0.469871 -0.429097 -0.116987  0.414751 -0.007861 -0.788327 -1.062836   \n",
       "111 -0.855878 -0.727290 -0.427368  0.801852  0.872556  0.934456  0.463320   \n",
       "\n",
       "         Vx12      Vx15    MaxO3v  \n",
       "0   -0.035606  0.356046 -0.233441  \n",
       "1   -0.858374 -0.468010 -0.126870  \n",
       "2    1.254113  0.790522 -0.304488  \n",
       "3    0.703625  0.542276  0.050748  \n",
       "4   -0.482687 -0.943449  0.832266  \n",
       "..        ...       ...       ...  \n",
       "107  0.219536  0.144795 -0.517629  \n",
       "108 -0.139768  0.115306 -0.695247  \n",
       "109  0.890786  0.914663 -0.482105  \n",
       "110 -0.771710 -0.825457  0.299413  \n",
       "111  0.204481 -0.825457 -0.268964  \n",
       "\n",
       "[112 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T9</th>\n",
       "      <th>T12</th>\n",
       "      <th>T15</th>\n",
       "      <th>Ne9</th>\n",
       "      <th>Ne12</th>\n",
       "      <th>Ne15</th>\n",
       "      <th>Vx9</th>\n",
       "      <th>Vx12</th>\n",
       "      <th>Vx15</th>\n",
       "      <th>MaxO3v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.947623e-16</td>\n",
       "      <td>-2.299748e-16</td>\n",
       "      <td>-1.586033e-17</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>-1.744636e-16</td>\n",
       "      <td>-1.586033e-16</td>\n",
       "      <td>3.172066e-17</td>\n",
       "      <td>1.586033e-17</td>\n",
       "      <td>-9.516197e-17</td>\n",
       "      <td>7.533656e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "      <td>1.004494e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.271236e+00</td>\n",
       "      <td>-1.870365e+00</td>\n",
       "      <td>-1.713231e+00</td>\n",
       "      <td>-1.907854e+00</td>\n",
       "      <td>-2.208904e+00</td>\n",
       "      <td>-2.080415e+00</td>\n",
       "      <td>-2.542636e+00</td>\n",
       "      <td>-2.251932e+00</td>\n",
       "      <td>-2.612687e+00</td>\n",
       "      <td>-1.725430e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.950420e-01</td>\n",
       "      <td>-7.272901e-01</td>\n",
       "      <td>-7.432910e-01</td>\n",
       "      <td>-7.465517e-01</td>\n",
       "      <td>-4.480695e-01</td>\n",
       "      <td>-7.883274e-01</td>\n",
       "      <td>-7.867737e-01</td>\n",
       "      <td>-7.019695e-01</td>\n",
       "      <td>-8.037238e-01</td>\n",
       "      <td>-6.952468e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.803663e-01</td>\n",
       "      <td>-2.427259e-01</td>\n",
       "      <td>-1.280717e-01</td>\n",
       "      <td>4.147509e-01</td>\n",
       "      <td>-7.860868e-03</td>\n",
       "      <td>7.306449e-02</td>\n",
       "      <td>1.329075e-01</td>\n",
       "      <td>-9.643571e-02</td>\n",
       "      <td>5.041172e-02</td>\n",
       "      <td>-2.867259e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.031874e-01</td>\n",
       "      <td>5.027576e-01</td>\n",
       "      <td>6.146254e-01</td>\n",
       "      <td>8.018518e-01</td>\n",
       "      <td>8.725563e-01</td>\n",
       "      <td>9.344564e-01</td>\n",
       "      <td>7.283376e-01</td>\n",
       "      <td>5.788388e-01</td>\n",
       "      <td>6.043282e-01</td>\n",
       "      <td>5.480777e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.779019e+00</td>\n",
       "      <td>2.975278e+00</td>\n",
       "      <td>2.853802e+00</td>\n",
       "      <td>1.188953e+00</td>\n",
       "      <td>1.312765e+00</td>\n",
       "      <td>1.365152e+00</td>\n",
       "      <td>2.445874e+00</td>\n",
       "      <td>2.942264e+00</td>\n",
       "      <td>2.391559e+00</td>\n",
       "      <td>2.679491e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T9           T12           T15           Ne9          Ne12  \\\n",
       "count  1.120000e+02  1.120000e+02  1.120000e+02  1.120000e+02  1.120000e+02   \n",
       "mean  -5.947623e-16 -2.299748e-16 -1.586033e-17 -1.110223e-16 -1.744636e-16   \n",
       "std    1.004494e+00  1.004494e+00  1.004494e+00  1.004494e+00  1.004494e+00   \n",
       "min   -2.271236e+00 -1.870365e+00 -1.713231e+00 -1.907854e+00 -2.208904e+00   \n",
       "25%   -6.950420e-01 -7.272901e-01 -7.432910e-01 -7.465517e-01 -4.480695e-01   \n",
       "50%   -1.803663e-01 -2.427259e-01 -1.280717e-01  4.147509e-01 -7.860868e-03   \n",
       "75%    5.031874e-01  5.027576e-01  6.146254e-01  8.018518e-01  8.725563e-01   \n",
       "max    2.779019e+00  2.975278e+00  2.853802e+00  1.188953e+00  1.312765e+00   \n",
       "\n",
       "               Ne15           Vx9          Vx12          Vx15        MaxO3v  \n",
       "count  1.120000e+02  1.120000e+02  1.120000e+02  1.120000e+02  1.120000e+02  \n",
       "mean  -1.586033e-16  3.172066e-17  1.586033e-17 -9.516197e-17  7.533656e-17  \n",
       "std    1.004494e+00  1.004494e+00  1.004494e+00  1.004494e+00  1.004494e+00  \n",
       "min   -2.080415e+00 -2.542636e+00 -2.251932e+00 -2.612687e+00 -1.725430e+00  \n",
       "25%   -7.883274e-01 -7.867737e-01 -7.019695e-01 -8.037238e-01 -6.952468e-01  \n",
       "50%    7.306449e-02  1.329075e-01 -9.643571e-02  5.041172e-02 -2.867259e-01  \n",
       "75%    9.344564e-01  7.283376e-01  5.788388e-01  6.043282e-01  5.480777e-01  \n",
       "max    1.365152e+00  2.445874e+00  2.942264e+00  2.391559e+00  2.679491e+00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d’appliquer un algorithme de régression linéaire, nous devons d’abord construire un jeu de données d’entraînement et un jeu de données de test que nous utiliserons pour l’évaluation d’un modèle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À la fin de l’exécution de l’instruction ci-dessus, les variables x_train et y_train vont représenter le jeu de données d’entraînement. x_train contiendra les variables explicatives et y_train contiendra la variable à prédire. De même, x_test et y_test représentent le jeu de données de test, x_test sera considéré comme étant des données à utiliser par un modèle pour prédire les valeurs contenues dans le vecteur y_test.\n",
    "\n",
    "Le paramètre test_size permet d’indiquer le taux des observations qui seront affectées au jeu de données de test. La fonction train_test_split() va tout simplement sélectionner de manière pseudo-aléatoire 20 % des observations de l’ensemble global de toutes les observations et les affecter au jeu de données de test.\n",
    "\n",
    "Cet algorithme de séparation de données va essayer d’équilibrer la répartition des données du vecteur y entre y_train et y_test. Autrement dit, la distribution associée aux données de y_train va être la plus proche possible de la distribution associée aux données de y_test. Par exemple, nous n’allons pas avoir dans y_train des valeurs de la variable MaxO3 plus grandes que toutes les valeurs dans y_test ou vice versa, un certain équilibre sera garanti par cette fonction train_test_split()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À ce stade, nous avons tous les ingrédients nécessaires pour entraîner un modèle à la prédiction de notre variable MaxO3. En effet, regression_alg représente un algorithme linéaire et x_train et y_train représentent des données propres et prêtes à être utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_alg = LinearRegression()\n",
    "regression_alg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette dernière instruction permet à l’algorithme regression_alg de s’entraîner pour comprendre comment les données de x_train peuvent être liées ensemble afin d’expliquer les résultats associés aux données de y_train. Chaque ligne de x_train explique la ligne correspondante dans y_train. Le résultat de cette instruction est un modèle qui peut être utilisé pour prédire la concentration de l’air en ozone en partant des valeurs des dix variables explicatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, pendant l’entraînement d’un modèle linéaire multiple, l’objectif recherché est l’estimation des coefficients qui seront associés à nos variables. Une fois que l’entraînement est achevé et avant d’évaluer un modèle sur le jeu de données de test, nous pouvons réaliser le calcul des métriques de performance de ce modèle sur le jeu de données d’entraînement. Cela va nous donner une idée de la qualité des prédictions du modèle acquise pendant l’entraînement.\n",
    "\n",
    "Dans notre exemple, nous allons utiliser les deux métriques de performance RMSE et le coefficient de détermination R2, abordés au premier chapitre, que nous allons expliquer en détail par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à la fonction regression_alg.predict(), la variable train_predictions va recevoir les prédictions de notre modèle sur les données x_train. La deuxième instruction de ce code permet de calculer la moyenne des carrés des erreurs, avec la fonction mean_squared_error(), et d’afficher sa racine carrée en utilisant la fonction sqrt() avec un niveau de précision de deux chiffres après la virgule. La deuxième instruction permet d’afficher le R2 du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 13.68\n",
      "R2_score = 0.75\n"
     ]
    }
   ],
   "source": [
    "train_predictions = regression_alg.predict(x_train)\n",
    "print(f\"RMSE = {round(sqrt(mean_squared_error(y_train, train_predictions)),2)}\")\n",
    "print(f\"R2_score = {round(r2_score(y_train, train_predictions),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces résultats montrent que notre modèle donne des prédictions qui s’écartent en moyenne de 14.17 des vraies observations contenues dans le jeu de données d’entraînement.\n",
    "\n",
    "La métrique de performance R2 nous donne une idée sur la comparaison de ce modèle avec un modèle théorique qui prédit toujours la valeur moyenne des valeurs observées. Comme nous l’avons dit précédemment, dans la suite de ce chapitre nous allons expliquer en détail le R2, mais pour l’instant il faut juste noter que plus le R2 est proche de la valeur 1, meilleures sont ses prédictions, et plus sa valeur est proche de la valeur 0, plus ses prédictions sont comparables avec les prédictions d’un modèle qui prédit toujours la valeur moyenne des observations, et ce quelles que soient les valeurs des variables explicatives. Dans ce dernier cas, ce modèle aurait un pouvoir de prédiction faible. Notez aussi que la valeur de R2 peut être négative et nous allons en découvrir les raisons dans la suite de ce chapitre. La valeur de R2 de notre modèle est 0.72, ce qui indique que notre modèle a un niveau de prédiction de bonne qualité.\n",
    "\n",
    "Rappelons que dans le code précédent les deux métriques RMSE et R2 ont été mesurées sur le jeu de données d’entraînement. Ces données sont connues par notre modèle puisque ce sont ces mêmes données qui ont été utilisées par notre algorithme pour estimer les paramètres du modèle. Voyons à présent quelles sont les valeurs de ces deux métriques de performance sur le jeu de données de test qui contient des données qui n’ont jamais été vues par notre modèle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 14.54\n",
      "R2_score = 0.76\n"
     ]
    }
   ],
   "source": [
    "test_predictions = regression_alg.predict(x_test)\n",
    "print(f\"RMSE = {round(sqrt(mean_squared_error(y_test, test_predictions)),2)}\")\n",
    "print(f\"R2_score = {round(r2_score(y_test, test_predictions),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces résultats montrent que notre modèle a un pouvoir de prédiction relativement intéressant puisque le R2 est proche de la valeur 1.\n",
    "\n",
    "Notez que ces résultats peuvent être sensiblement différents d’une exécution à une autre. En effet, les différences d’une exécution à une autre dans notre cas précis sont dues à la fonction train_test_split qui construit des jeux de données d’entraînement et de test différents selon les exécutions. Comme nous ne disposons pas d’un grand volume de données, même des petites différences entre les données d’entraînement et celles de test peuvent jouer un rôle suffisamment important pour aboutir à des modèles très différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04474989, 11.01583149, -0.04733771, -4.33870782, -0.587577  ,\n",
       "        1.2871011 ,  4.02956714,  0.91297309,  1.46989522, 10.07493662])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_alg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.50701761505466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_alg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter( y_test, test_predictions,  color='black')\n",
    "plt.title(\"les prédictions du modèle vs la réalité\")\n",
    "plt.xlabel(\"les valeurs observées\")\n",
    "plt.ylabel(\"Les prédictions\")\n",
    "plt.plot([40.0, 160.0], [40.0, 160.0], 'red', lw=1)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme les résultats obtenus dans notre exemple peuvent sensiblement être différents d’une exécution à une autre, il serait intéressant de se poser la question sur le pouvoir prédictif de notre modèle une fois déployé en production. En effet, on aimerait bien se faire une idée de la qualité des prédictions de notre modèle qui sera la plus proche possible de la réalité.\n",
    "\n",
    "Pour cela, nous pouvons exécuter notre programme plusieurs fois et calculer le RMSE et le R2 à chaque exécution puis réaliser la moyenne des ces deux métriques relatives à toutes les exécutions. Cela nous donnera une idée plus précise de la qualité moyenne que va avoir notre modèle en production. Pour calculer les moyennes de RMSE et de R2 sur plusieurs exécutions, suivez les étapes ci-après."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_result(nb_run):\n",
    "    average_rmse = 0\n",
    "    average_r2 = 0\n",
    "    for i_run in range(nb_run):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "        \n",
    "        regression_alg = LinearRegression()\n",
    "        regression_alg.fit(x_train, y_train)\n",
    "        \n",
    "        test_predictions = regression_alg.predict(x_test)\n",
    "        \n",
    "        i_run_rmse = sqrt(mean_squared_error(y_test, test_predictions))\n",
    "        i_run_r2 = r2_score(y_test, test_predictions)\n",
    "        \n",
    "        print(f\"Run {i_run} : RMSE = {round(i_run_rmse,2)} - R2_score = {round(i_run_r2,2)}\")\n",
    "        \n",
    "        average_rmse = average_rmse + i_run_rmse\n",
    "        average_r2 = average_r2 + i_run_r2\n",
    "    \n",
    "    average_rmse = average_rmse / nb_run\n",
    "    average_r2 = average_r2 / nb_run\n",
    "    \n",
    "    print(f\"Moyenne : RMSE = {round(average_rmse,2)} - R2_score = {round(average_r2,2)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction permet d’automatiser les exécutions de la fonction regression_alg.fit() avec des jeux de données d’entraînement et de test différents à chaque fois. En effet, nous savons qu’à chaque exécution de cette fonction les données des variables x_train, x_test, y_train, y_test sont différentes.\n",
    "\n",
    "Cette fonction commence par l’initialisation des deux moyennes average_rmse et average_r2 avec la valeur 0. Puis, dans une boucle for, la variable i_run prend tour à tour les valeurs de 0 jusqu’à la valeur (nb_run-1), avec nb_run qui correspond à l’unique paramètre de cette fonction et qui représente le nombre d’exécutions que nous souhaitons réaliser.\n",
    "\n",
    "Au début de chaque itération de cette boucle, la fonction train_test_split(...) génère des données x_train, y_train, x_test et y_test différentes. Le reste du code de cette boucle est décrit comme suit :\n",
    "\n",
    "    Une instance de l’algorithme est créée avec la fonction LinearRegression().\n",
    "\n",
    "    La fonction fit() est lancée sur le jeu de données d’entraînement x_train, y_train.\n",
    "\n",
    "    La fonction predict() est utilisée pour effectuer des prédictions sur les données de test x_test.\n",
    "\n",
    "    La métrique RMSE est calculée pour l’itération en cours et stockée dans la variable i_run_rmse.\n",
    "\n",
    "    Le RMSE et le R2 de l’exécution en cours sont affichés.\n",
    "\n",
    "    La variable average_rmse est mise à jour pour avoir le cumul de tous les RMSE de toutes les exécutions.\n",
    "\n",
    "Et enfin, à la fin de cette fonction, les moyennes de average_rmse et de average_r2 sont calculées et affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 : RMSE = 10.69 - R2_score = 0.86\n",
      "Run 1 : RMSE = 12.51 - R2_score = 0.82\n",
      "Run 2 : RMSE = 17.0 - R2_score = 0.64\n",
      "Run 3 : RMSE = 13.84 - R2_score = 0.63\n",
      "Run 4 : RMSE = 14.12 - R2_score = 0.73\n",
      "Run 5 : RMSE = 15.44 - R2_score = 0.76\n",
      "Run 6 : RMSE = 15.41 - R2_score = 0.68\n",
      "Run 7 : RMSE = 9.98 - R2_score = 0.81\n",
      "Run 8 : RMSE = 18.95 - R2_score = 0.6\n",
      "Run 9 : RMSE = 15.07 - R2_score = 0.76\n",
      "Run 10 : RMSE = 18.7 - R2_score = 0.1\n",
      "Run 11 : RMSE = 15.22 - R2_score = 0.76\n",
      "Run 12 : RMSE = 11.94 - R2_score = 0.79\n",
      "Run 13 : RMSE = 14.42 - R2_score = 0.64\n",
      "Run 14 : RMSE = 15.79 - R2_score = 0.77\n",
      "Run 15 : RMSE = 13.24 - R2_score = 0.8\n",
      "Run 16 : RMSE = 12.9 - R2_score = 0.65\n",
      "Run 17 : RMSE = 12.63 - R2_score = 0.64\n",
      "Run 18 : RMSE = 10.42 - R2_score = 0.83\n",
      "Run 19 : RMSE = 13.45 - R2_score = 0.6\n",
      "Run 20 : RMSE = 14.39 - R2_score = 0.73\n",
      "Run 21 : RMSE = 13.77 - R2_score = 0.71\n",
      "Run 22 : RMSE = 11.99 - R2_score = 0.76\n",
      "Run 23 : RMSE = 10.4 - R2_score = 0.84\n",
      "Run 24 : RMSE = 18.48 - R2_score = 0.6\n",
      "Run 25 : RMSE = 16.25 - R2_score = 0.68\n",
      "Run 26 : RMSE = 13.08 - R2_score = 0.76\n",
      "Run 27 : RMSE = 16.4 - R2_score = 0.69\n",
      "Run 28 : RMSE = 10.79 - R2_score = 0.88\n",
      "Run 29 : RMSE = 15.09 - R2_score = 0.53\n",
      "Run 30 : RMSE = 16.83 - R2_score = 0.75\n",
      "Run 31 : RMSE = 12.52 - R2_score = 0.76\n",
      "Run 32 : RMSE = 12.73 - R2_score = 0.7\n",
      "Run 33 : RMSE = 11.54 - R2_score = 0.71\n",
      "Run 34 : RMSE = 14.07 - R2_score = 0.78\n",
      "Run 35 : RMSE = 17.29 - R2_score = 0.59\n",
      "Run 36 : RMSE = 14.19 - R2_score = 0.76\n",
      "Run 37 : RMSE = 17.7 - R2_score = 0.71\n",
      "Run 38 : RMSE = 13.31 - R2_score = 0.72\n",
      "Run 39 : RMSE = 18.72 - R2_score = 0.63\n",
      "Run 40 : RMSE = 20.11 - R2_score = 0.53\n",
      "Run 41 : RMSE = 10.48 - R2_score = 0.86\n",
      "Run 42 : RMSE = 13.43 - R2_score = 0.81\n",
      "Run 43 : RMSE = 16.71 - R2_score = 0.29\n",
      "Run 44 : RMSE = 10.32 - R2_score = 0.89\n",
      "Run 45 : RMSE = 14.49 - R2_score = 0.79\n",
      "Run 46 : RMSE = 10.92 - R2_score = 0.72\n",
      "Run 47 : RMSE = 13.96 - R2_score = 0.76\n",
      "Run 48 : RMSE = 12.25 - R2_score = 0.84\n",
      "Run 49 : RMSE = 11.07 - R2_score = 0.71\n",
      "Run 50 : RMSE = 17.98 - R2_score = 0.76\n",
      "Run 51 : RMSE = 9.91 - R2_score = 0.89\n",
      "Run 52 : RMSE = 10.68 - R2_score = 0.85\n",
      "Run 53 : RMSE = 12.63 - R2_score = 0.51\n",
      "Run 54 : RMSE = 18.18 - R2_score = 0.49\n",
      "Run 55 : RMSE = 15.14 - R2_score = 0.78\n",
      "Run 56 : RMSE = 18.71 - R2_score = 0.56\n",
      "Run 57 : RMSE = 11.84 - R2_score = 0.8\n",
      "Run 58 : RMSE = 15.42 - R2_score = 0.58\n",
      "Run 59 : RMSE = 11.68 - R2_score = 0.48\n",
      "Run 60 : RMSE = 13.44 - R2_score = 0.77\n",
      "Run 61 : RMSE = 13.11 - R2_score = 0.78\n",
      "Run 62 : RMSE = 15.21 - R2_score = 0.62\n",
      "Run 63 : RMSE = 15.78 - R2_score = 0.38\n",
      "Run 64 : RMSE = 18.03 - R2_score = 0.7\n",
      "Run 65 : RMSE = 14.07 - R2_score = 0.77\n",
      "Run 66 : RMSE = 12.84 - R2_score = 0.77\n",
      "Run 67 : RMSE = 13.54 - R2_score = 0.68\n",
      "Run 68 : RMSE = 13.46 - R2_score = 0.6\n",
      "Run 69 : RMSE = 15.83 - R2_score = 0.67\n",
      "Run 70 : RMSE = 20.01 - R2_score = 0.28\n",
      "Run 71 : RMSE = 14.74 - R2_score = 0.75\n",
      "Run 72 : RMSE = 16.34 - R2_score = 0.65\n",
      "Run 73 : RMSE = 16.26 - R2_score = 0.68\n",
      "Run 74 : RMSE = 19.17 - R2_score = 0.2\n",
      "Run 75 : RMSE = 16.79 - R2_score = 0.73\n",
      "Run 76 : RMSE = 21.03 - R2_score = 0.58\n",
      "Run 77 : RMSE = 17.5 - R2_score = 0.68\n",
      "Run 78 : RMSE = 20.51 - R2_score = -0.02\n",
      "Run 79 : RMSE = 12.11 - R2_score = 0.72\n",
      "Run 80 : RMSE = 10.29 - R2_score = 0.84\n",
      "Run 81 : RMSE = 19.74 - R2_score = 0.65\n",
      "Run 82 : RMSE = 18.82 - R2_score = 0.63\n",
      "Run 83 : RMSE = 14.22 - R2_score = 0.4\n",
      "Run 84 : RMSE = 16.0 - R2_score = 0.6\n",
      "Run 85 : RMSE = 20.61 - R2_score = 0.58\n",
      "Run 86 : RMSE = 17.04 - R2_score = 0.38\n",
      "Run 87 : RMSE = 15.53 - R2_score = 0.5\n",
      "Run 88 : RMSE = 14.66 - R2_score = 0.57\n",
      "Run 89 : RMSE = 15.86 - R2_score = 0.42\n",
      "Run 90 : RMSE = 18.67 - R2_score = 0.59\n",
      "Run 91 : RMSE = 15.02 - R2_score = 0.67\n",
      "Run 92 : RMSE = 14.7 - R2_score = 0.8\n",
      "Run 93 : RMSE = 15.01 - R2_score = 0.77\n",
      "Run 94 : RMSE = 19.93 - R2_score = 0.58\n",
      "Run 95 : RMSE = 12.26 - R2_score = 0.78\n",
      "Run 96 : RMSE = 11.57 - R2_score = 0.87\n",
      "Run 97 : RMSE = 13.82 - R2_score = 0.74\n",
      "Run 98 : RMSE = 18.28 - R2_score = 0.72\n",
      "Run 99 : RMSE = 18.9 - R2_score = 0.69\n",
      "Moyenne : RMSE = 14.88 - R2_score = 0.67\n"
     ]
    }
   ],
   "source": [
    "average_result(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La moyenne de RMSE sur les dix modèles est égale à 17.17 et la moyenne de R2 sur les dix modèles est égale à 0.65. Sachant que nous ne disposons au total que de 112 observations dans l’ensemble du dataset utilisé, nous pouvons supposer que cette moyenne du RMSE sera plus au moins proche de la moyenne du RMSE qui sera obtenue en production. La même supposition peut être émise à l’égard de la moyenne du R2. En effet, lorsque nous avons utilisé la fonction train_test_split(), nous avons fixé le paramètre test_size à 20 % ; c’est-à-dire que chacune des dix itérations sera réalisée avec un nombre d’observations dans le jeu de données de test égal, plus ou moins, à 22. Avec un peu de chance, chacune des 112 observations aura l’occasion d’appartenir aux données de test à un moment donné sur les dix itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les indices de train_index =  [ 56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111]\n",
      "Les indices de test_index =  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55]\n",
      "\n",
      "\n",
      "\n",
      "Les indices de train_index =  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55]\n",
      "Les indices de test_index =  [ 56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"Les indices de train_index = \", train_index)\n",
    "    print(\"Les indices de test_index = \",test_index)\n",
    "    print(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les indices de train_index =  [  1   4   7   8  10  11  14  16  17  18  19  20  28  29  32  34  36  37\n",
      "  38  43  44  45  47  49  50  52  53  54  55  58  59  61  62  64  65  67\n",
      "  70  76  77  78  80  84  86  88  91  92  96  97  98  99 100 101 102 103\n",
      " 104 111]\n",
      "Les indices de test_index =  [  0   2   3   5   6   9  12  13  15  21  22  23  24  25  26  27  30  31\n",
      "  33  35  39  40  41  42  46  48  51  56  57  60  63  66  68  69  71  72\n",
      "  73  74  75  79  81  82  83  85  87  89  90  93  94  95 105 106 107 108\n",
      " 109 110]\n",
      "\n",
      "\n",
      "\n",
      "Les indices de train_index =  [  0   2   3   5   6   9  12  13  15  21  22  23  24  25  26  27  30  31\n",
      "  33  35  39  40  41  42  46  48  51  56  57  60  63  66  68  69  71  72\n",
      "  73  74  75  79  81  82  83  85  87  89  90  93  94  95 105 106 107 108\n",
      " 109 110]\n",
      "Les indices de test_index =  [  1   4   7   8  10  11  14  16  17  18  19  20  28  29  32  34  36  37\n",
      "  38  43  44  45  47  49  50  52  53  54  55  58  59  61  62  64  65  67\n",
      "  70  76  77  78  80  84  86  88  91  92  96  97  98  99 100 101 102 103\n",
      " 104 111]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"Les indices de train_index = \", train_index)\n",
    "    print(\"Les indices de test_index = \", test_index)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre d'éléments dans train_index = 74\n",
      "Le nombre d'éléments dans test_index = 38\n",
      "\n",
      "Le nombre d'éléments dans train_index = 75\n",
      "Le nombre d'éléments dans test_index = 37\n",
      "\n",
      "Le nombre d'éléments dans train_index = 75\n",
      "Le nombre d'éléments dans test_index = 37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=False)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(f\"Le nombre d'éléments dans train_index = {train_index.shape[0]}\")\n",
    "    print(f\"Le nombre d'éléments dans test_index = {test_index.shape[0]}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluate_model(index_fold, x_train, x_test,  y_train, y_test):\n",
    "    regression_alg = LinearRegression()\n",
    "    regression_alg.fit(x_train, y_train)\n",
    "    test_predictions = regression_alg.predict(x_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, test_predictions))\n",
    "    r2 = r2_score(y_test, test_predictions)\n",
    "    print(f\"Run {index_fold} : RMSE = {round(rmse,2)} - R2_score = {round(r2,2)}\")\n",
    "    return (rmse, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 : RMSE = 15.25 - R2_score = 0.55\n",
      "Run 1 : RMSE = 18.13 - R2_score = 0.2\n",
      "Run 2 : RMSE = 19.2 - R2_score = 0.74\n",
      "Run 3 : RMSE = 16.31 - R2_score = 0.68\n",
      "Run 4 : RMSE = 8.4 - R2_score = 0.62\n",
      "Moyenne : RMSE = 15.46 - R2_score = 0.56\n"
     ]
    }
   ],
   "source": [
    "nb_model = 5\n",
    "kf = KFold(n_splits=nb_model, shuffle=False)\n",
    "index_fold = 0 \n",
    "average_rmse = 0\n",
    "average_r2 = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    current_rmse, current_r2 = create_evaluate_model(index_fold, x_train, x_test, y_train, y_test)\n",
    "    average_rmse = average_rmse + current_rmse\n",
    "    average_r2 = average_r2 + current_r2\n",
    "    index_fold = index_fold + 1\n",
    "    \n",
    "average_rmse = average_rmse / nb_model\n",
    "average_r2 = average_r2 / nb_model\n",
    "print(f\"Moyenne : RMSE = {round(average_rmse,2)} - R2_score = {round(average_r2,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
